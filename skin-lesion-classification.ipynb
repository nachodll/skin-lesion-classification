{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEh94VFN1rbQ"
      },
      "source": [
        "# 1. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "dyoqzkQbKjLq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# From here, add any libraries that you might need for the rest of your code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DskoSTp-KjLr"
      },
      "source": [
        "# 2. Load and pre-process the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IF YOU USE GOOGLE COLAB AND HAVE THE DATA STORED ON YOUR GOOGLE DRIVE:\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive') # mounts your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmhFCLoo2yc4",
        "outputId": "38f83e49-a2d9-4db2-d221-34eb52c16205"
      },
      "outputs": [],
      "source": [
        "# SET THE PATHS BASED ON WHERE YOU STORED THE DATASET:\n",
        "\n",
        "# IF YOU USE GOOGLE COLAB AND HAVE THE DATA STORED ON YOUR GOOGLE DRIVE:\n",
        "# !cp -r \"/content/drive/MyDrive/.../Skin_Lesion_Dataset/Train\" /content/  # copies the data from your Google Drive to colab's VM (may take a few mins; set path to your Google directory). \n",
        "# dataset_dir = \"/content/Train/\" # points to the local copy on colab's virtual machine (VM)\n",
        "\n",
        "# IF YOU USE YOUR OWN COMPUTER:\n",
        "dataset_dir = \"C:/.../Skin_Lesion_Dataset/Train/\" # if you run the code locally, set this path to the directory where you stored the dataset.\n",
        "\n",
        "# LIST THE CLASSES THAT EXIST WITHIN THIS DATASET:\n",
        "CLASS_LABELS  = ['AK', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'SCC', 'VASC'] # creates a list of the 8 classes in this dataset (the dataset contains images of 8 types of skin lesion)\n",
        "# note: class names are abbreviations for:\n",
        "# [\"Actinic Keratoses\", \"Basal Cell Carcinoma\", \"Benign Keratosis-like Lesions\", \"Dermatofibroma\", \"Melanoma\", \"Nevus\", \"Squamous Cell Carcinoma\", \"Vascular Lesions\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N08AR8963AJ5",
        "outputId": "518b96db-573e-4b5d-8575-68f55f9b3e31"
      },
      "outputs": [],
      "source": [
        "## IMPORTANT: please remember that you are not allowed to change the\n",
        "## loading and preprocessing code to improve model performance for this assignment.\n",
        "\n",
        "# LOAD AND PREPROCESS THE DATA:\n",
        "\n",
        "# set size of images (in pixels) after resizing\n",
        "IMG_HEIGHT = 42\n",
        "IMG_WIDTH = 42\n",
        "\n",
        "# set batch size\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# set relative sizes of the test and val set\n",
        "TEST_SIZE = 0.2   # 20% of all 27.934 images will be used for testing the model\n",
        "VAL_SIZE = 0.2    # of the remaining images, 20% will be used for validation and 80% for training\n",
        "\n",
        "# function for adding noise to the images\n",
        "def add_noise(img):\n",
        "    std_coeff = 20 * np.random.random()\n",
        "    noise = np.random.normal(0, std_coeff, img.shape)\n",
        "    img += noise\n",
        "    img = np.clip(img, 0., 255.)\n",
        "    return img\n",
        "\n",
        "# build dataframe with file paths and labels\n",
        "all_files = []\n",
        "all_labels = []\n",
        "\n",
        "for class_name in sorted(os.listdir(dataset_dir)):\n",
        "    class_path = os.path.join(dataset_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        for fname in os.listdir(class_path):\n",
        "            fpath = os.path.join(class_path, fname)\n",
        "            all_files.append(fpath)\n",
        "            all_labels.append(class_name)\n",
        "\n",
        "df = pd.DataFrame({\"filename\": all_files, \"class\": all_labels})\n",
        "\n",
        "# split the data into train / val / test\n",
        "trainval_df, test_df = train_test_split(df, test_size=TEST_SIZE, stratify=df[\"class\"], random_state=31) # split all data into trainval + test\n",
        "train_df, val_df   = train_test_split(trainval_df, test_size=VAL_SIZE, stratify=trainval_df[\"class\"], random_state=31)  # split trainval data into train + val\n",
        "\n",
        "# define generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=add_noise) # note: noise is only added to the train samples.\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# apply generators\n",
        "train_data = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"class\",\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=7\n",
        ")\n",
        "\n",
        "val_data = val_test_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"class\",\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=7\n",
        ")\n",
        "\n",
        "test_data = val_test_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"class\",\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"Data loading completed successfully.\")\n",
        "print(f\"Number of training samples: {train_data.samples}\")\n",
        "print(f\"Number of validation samples: {val_data.samples}\")\n",
        "print(f\"Number of test samples: {test_data.samples}\")\n",
        "print(f\"Class names: {train_data.class_indices}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tsGT9LZKjLu"
      },
      "source": [
        "# 3. Visualise data and plot data distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yavQhpjKKjLx"
      },
      "source": [
        "# 4. Model Design and Train and Evaluation functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEOuwcZFKjLy"
      },
      "source": [
        "# 5. Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjbpc8FLgHgy"
      },
      "source": [
        "# 6. Model evaluation"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 1885224,
          "sourceId": 3082941,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30775,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "dl_course_assignment_env_py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
